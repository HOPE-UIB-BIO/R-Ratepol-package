---
title: "Example of full workflow"
output: 
  rmarkdown::html_vignette:
    fig_width: 7
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Example of full workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
```

This workflow should show full strength of *RRatepol package* and serve as step by 
step guidance starting from downloading dataset from Neotoma, building age-depth
models, to estimating rate-of-change using age uncertainty.

:warning: **This workflow is only meant as example**: There are several additional steps for data reparation which should be done to really use the data from Neotoma!

## import packages

```{r setup, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(pander)
library(RRatepol)
library(neotoma)
library(Bchron)
library(janitor)
```

## Download the dataset *Glendalough Valley* from Neotoma

```{r download_of_data, results='hide', warning=FALSE, message=FALSE}
gl_dataset_download <- 
  neotoma::get_download(17334)

chronology_id <- 
  gl_dataset_download[[1]]$sample.meta$chronology.id %>% 
  unique()

gl_chron_control_table_download <- 
  neotoma::get_chroncontrol(chronology_id)

```

## Prepare the pollen counts

```{r count_preparation, results='hide', warning=FALSE}
gl_counts <- 
  gl_dataset_download[[1]]$counts 

gl_taxon_list <- 
  gl_dataset_download[[1]]$taxon.list

gl_taxon_list_selected <- 
gl_taxon_list %>% 
  dplyr::filter(variable.element == "pollen")

gl_counts_selected <-
  gl_counts %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(., var = "sample_id") %>% 
  tibble::as_tibble() %>% 
  dplyr::select(sample_id, dplyr::any_of(gl_taxon_list_selected$taxon.name)) %>% 
  janitor::clean_names() 

head(gl_counts_selected)[,1:5]

```

```{r count_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(gl_counts_selected)[,1:5])

```

Here, we strongly advocate that attention should be paid to the section of 
ecological ecological group, as well, as harmonisation of the pollen taxa.
However, that is not subject of this workflow.

## Preparation of the levels

### Sample depth

Extract depth for each level

```{r level_preparion, results='hide', warning=FALSE}
gl_level <-
  gl_dataset_download[[1]]$sample.meta %>% 
  tibble::as_tibble() %>% 
  dplyr::rename(sample_id = sample.id) %>% 
  dplyr::select(sample_id, depth) %>% 
  dplyr::mutate_if(is.integer, as.character)

head(gl_level)

```

```{r level_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(gl_level))

```


### Age depth modelling

We will recalculate new age-depth model 'de novo' using *Bchron* package. In this 
toy example we will use only iteration multiplier (*i_multiplier*) of 0.5 to 
reduce the computation time. However, we strongly recommend to increase it to 5
for any normal age-depth model construction.

Prepare chron.control table and run Bchron
Here we only present few of the important steps of preparation of chron.control 
table. There are many more potential issues issues but solving those is not 
the focus of this workflow.

```{r chron_control_prepare, results='hide', warning=FALSE}
gl_chron_control_table <-
  gl_chron_control_table_download$chron.control %>% 
   # here we calculate the error as the avarage as the age.old and age age.young
  dplyr::mutate(
    error = round((age.old - age.young) / 2)) %>% 
  # as Bchron cannot accept error of 0, we need to replace the value with 1 
  dplyr::mutate(
    error = replace(error, error == 0, 1)) %>% 
  # we need to specifify which calibration curve should be used for what point
  dplyr::mutate(
    curve = ifelse(control.type == "Radiocarbon", "intcal20", "normal")) %>% 
  dplyr::select(chron.control.id, age, error, depth, thickness, control.type, curve)

gl_chron_control_table

```


```{r chron_control_show, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(gl_chron_control_table)
```

```{r bchron, results='hide', warning=FALSE, message=FALSE}
i_multiplier <- 0.5 # increase to 5

n_iteration_default <- 10e3
n_burn_default <- 2e3
n_thin_default <- 8

n_iteration <- n_iteration_default * i_multiplier
n_burn <- n_burn_default * i_multiplier
n_thin <- n_thin_default * i_multiplier

gl_bchron <- 
  Bchron::Bchronology(
    ages = gl_chron_control_table$age,
    ageSds = gl_chron_control_table$error,
    positions = gl_chron_control_table$depth,
    calCurves = gl_chron_control_table$curve,
    positionThicknesses = gl_chron_control_table$thickness,
    iterations = n_iteration,
    burn = n_burn,
    thin = n_thin)

```

```{r bchron_figure, results='markup', warning=FALSE}
plot(gl_bchron)
```

Predict ages

```{r predic_ages, results='hide', warning=FALSE}
age_position <- 
  Bchron:::predict.BchronologyRun(gl_bchron, newPositions = gl_level$depth)
  
age_uncertainties <- 
  age_position %>% 
  as.data.frame() %>% 
  dplyr::mutate_all(., as.integer) %>% 
  as.matrix()
  
colnames(age_uncertainties) <- gl_level$sample_id

gl_level_predicted <- 
  gl_level %>% 
  dplyr::mutate(
    age = apply(
    age_uncertainties, 2,
    stats::quantile,
    probs = 0.5)
  )

head(gl_level_predicted)

```

```{r level_predicted_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(gl_level_predicted))

```

## Estimation Rate-of-Change

Here we use the the prepared data to estimate the rate of vegetation change. We
will use the method of the *binning with the mowing window*, *Shepard's 5-term filter* 
as data smoothing *Chi-squared coefficient* as dissimilarity coefficient.
This is again a toy example for a quick computation and we would recommend 
increasing the *randomisations* to 10.000 for any real estimation. 

```{r roc, results='hide', warning=FALSE, message=FALSE}
randomisations <- 100 # increase to 10e3

gl_roc <-
    RRatepol::fc_estimate_RoC(
      data_source_community = gl_counts_selected,
      data_source_age = gl_level_predicted,
      age_uncertainty = age_uncertainties,
      smooth_method = "shep",
      DC = "chisq",
      Working_Units = "MW",
      bin_size = 500,
      Number_of_shifts  = 5,
      standardise = TRUE,
      N_individuals = 150,
      rand = randomisations,
      use_parallel = FALSE # use_parallel = TRUE to use parallel calculation
      ) 

```

### Detect peak-points and plot the results

We will detect significant peak-points using *Non-linear* method

```{r peak_points, results='hide', warning=FALSE}
gl_roc_peaks <-
  RRatepol::fc_detect_peak_points(
    data_source = gl_roc,
    sel_method = "trend_non_linear")
```

Plot the estimates with showing both the peak-points 

```{r roc_figure, results='markup', echo=TRUE}
RRatepol::fc_plot_RoC_sequence(
  data_source = gl_roc_peaks,
  Peaks = TRUE,
  trend = "trend_non_linear")
```

